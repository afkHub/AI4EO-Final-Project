{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f838782-71db-45b3-8138-be8f62de1092",
   "metadata": {},
   "source": [
    "**Description** \n",
    "\n",
    "The function in this script converts the data stored in .npy files into images with .tif extension and saves them in the main file *\"only1img4allHHc5\"* with the corresponding file names.\n",
    "\n",
    "\n",
    "https://ieee-dataport.org/open-access/si-stsar-7\n",
    "The source data in the link was used.\n",
    "\n",
    "As mentioned link below, there are 6 time steps for each data. In this code, the 6th time step and HH polarization is chosen for the output image.\n",
    "\n",
    "\n",
    "https://ieee-dataport.s3.amazonaws.com/docs/70273/Readme.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAJOHYI4KJCE6Q7MIQ%2F20240829%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240829T163630Z&X-Amz-SignedHeaders=Host&X-Amz-Expires=86400&X-Amz-Signature=778fccc9fce2a441c5c73181e69758eca45883e3142d250acd91a9c02d922977\n",
    "\n",
    "*Additional information*: In the rest of the project a copy of the main folder “only1img4allHHc5 - Copy” was created manually.\n",
    "Afterwards, the data of the \"GI_6s\", \"GWI_6s\" and \"NI_6s\" folders in the copy folder were combined into one folder \"GI_6s - GWI_6s - NI_6s\". The reason for this is to increase the accuracy of the DL model and is explained in the final report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1e168b-3d50-48af-823a-0693358f4467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "import os\n",
    "import random\n",
    "\n",
    "def npy_to_img(npy_file):\n",
    "\n",
    "    #load the .npy file\n",
    "    img_array = np.load(npy_file)\n",
    "\n",
    "    #extract the file name without the extension\n",
    "    file_name = os.path.splitext(os.path.basename(npy_file))[0]\n",
    "\n",
    "    #define the main directory\n",
    "    main_dir = 'only1img4allHHc5'\n",
    "\n",
    "    #create the main directory if it doesnot exist\n",
    "    if not os.path.exists(main_dir):\n",
    "        os.makedirs(main_dir)\n",
    "\n",
    "    #create a subfolder for the current .npy file within the main directory\n",
    "    subfolder_path = os.path.join(main_dir, file_name)\n",
    "    if not os.path.exists(subfolder_path):\n",
    "        os.makedirs(subfolder_path)\n",
    "\n",
    "    #assuming img_array is of shape (num_sets, num_images_per_set, height, width, channels)\n",
    "    num_sets = img_array.shape[0]\n",
    "    num_images_per_set = img_array.shape[1]\n",
    "\n",
    "    for set_idx in range(num_sets):\n",
    "        #there are 6 time steps, here index 5 selected\n",
    "        img_idx = 5 #6th time step selected \n",
    "        \"\"\"\n",
    "        # Select a random index between 0 and 5\n",
    "        img_idx = random.randint(0, num_images_per_set - 1)\n",
    "        \"\"\"\n",
    "        \n",
    "        #extract the image\n",
    "        img = img_array[set_idx, img_idx]\n",
    "\n",
    "        #ensuring the data type is float32 like SNAP software extracts\n",
    "        img = img.astype(np.float32)\n",
    "\n",
    "        selected_columns = [img[i, :, 0] for i in range(img.shape[0])] #HH band selected. if the value was 1 it would be HV band\n",
    "\n",
    "        combine = np.vstack(selected_columns) #combine all the columns together and create the image. what a strange file storage...\n",
    "\n",
    "        \"\"\" Big Mistake!\n",
    "        # normalization for standardized data\n",
    "        #subtract the minimum value to make it positive\n",
    "        sar_image_positive = combine - np.min(combine)\n",
    "        #normalize between values 0 and 1\n",
    "        sar_image_normalized = (sar_image_positive - np.min(sar_image_positive)) / (np.max(sar_image_positive) - np.min(sar_image_positive))\n",
    "        \"\"\"\n",
    "        \n",
    "        #save the image as a .tif file\n",
    "        tiff.imwrite(f'{subfolder_path}/{file_name}_{set_idx}_{img_idx}.tif', combine)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db574033-5503-4611-862a-3869ecc50f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting images from the dataset of the NI type ice\n",
    "npy_to_img('NI_6s.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9da0d7c-056e-41a2-8525-c8626e4e484d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting other 6 data type\n",
    "npy_to_img('ThickFI_6s.npy')\n",
    "npy_to_img('ThinFI_6s.npy')\n",
    "npy_to_img('OW_6s.npy')\n",
    "npy_to_img('GWI_6s.npy')\n",
    "npy_to_img('GI_6s.npy')\n",
    "npy_to_img('MediumFI_6s.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27b38bd-f714-445b-aeb6-c5513c4cfe9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
